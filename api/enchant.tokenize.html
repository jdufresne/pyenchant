

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>enchant.tokenize: String tokenization functions for PyEnchant &mdash; PyEnchant 3.1.1 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="enchant.utils: Misc utilities for the enchant package" href="enchant.utils.html" />
    <link rel="prev" title="enchant.checker: High-level spellchecking functionality" href="enchant.checker.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> PyEnchant
          

          
          </a>

          
            
            
              <div class="version">
                3.1.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial.html">Tutorial</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">API Listing</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="index.html#full-list">Full list</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html#by-module">By module</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="enchant.html">enchant:  Access to the enchant spellchecking library</a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.checker.html">enchant.checker:  High-level spellchecking functionality</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">enchant.tokenize:    String tokenization functions for PyEnchant</a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.utils.html">enchant.utils:    Misc utilities for the enchant package</a></li>
<li class="toctree-l3"><a class="reference internal" href="enchant.pypwl.html">pypwl:  pure-python personal word list in the style of Enchant</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../shootout.html">Provider Shootout</a></li>
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">Changelog</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">PyEnchant</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="index.html">API Listing</a> &raquo;</li>
        
      <li>enchant.tokenize:    String tokenization functions for PyEnchant</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/api/enchant.tokenize.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <span class="target" id="module-enchant.tokenize"></span><div class="section" id="enchant-tokenize-string-tokenization-functions-for-pyenchant">
<h1>enchant.tokenize:    String tokenization functions for PyEnchant<a class="headerlink" href="#enchant-tokenize-string-tokenization-functions-for-pyenchant" title="Permalink to this headline">¶</a></h1>
<p>An important task in spellchecking is breaking up large bodies of
text into their constituent words, each of which is then checked
for correctness.  This package provides Python functions to split
strings into words according to the rules of a particular language.</p>
<p>Each tokenization function accepts a string as its only positional
argument, and returns an iterator that yields tuples of the following
form, one for each word found:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="o">&lt;</span><span class="n">word</span><span class="o">&gt;</span><span class="p">,</span><span class="o">&lt;</span><span class="n">pos</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
<p>The meanings of these fields should be clear: &lt;word&gt; is the word
that was found and &lt;pos&gt; is the position within the text at which
the word began (zero indexed, of course).  The function will work
on any string-like object that supports array-slicing; in particular
character-array objects from the ‘array’ module may be used.</p>
<p>The iterator also provides the attribute ‘offset’ which gives the current
position of the tokenizer inside the string being split, and the method
‘set_offset’ for manually adjusting this position.  This can be used for
example if the string’s contents have changed during the tokenization
process.</p>
<p>To obtain an appropriate tokenization function for the language
identified by &lt;tag&gt;, use the function ‘get_tokenizer(tag)’:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tknzr</span> <span class="o">=</span> <span class="n">get_tokenizer</span><span class="p">(</span><span class="s2">&quot;en_US&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span><span class="n">pos</span><span class="p">)</span> <span class="ow">in</span> <span class="n">tknzr</span><span class="p">(</span><span class="s2">&quot;text to be tokenized goes here&quot;</span><span class="p">)</span>
    <span class="n">do_something</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</pre></div>
</div>
<p>This library is designed to be easily extendible by third-party
authors.  To register a tokenization function for the language
&lt;tag&gt;, implement it as the function ‘tokenize’ within the
module enchant.tokenize.&lt;tag&gt;.  The ‘get_tokenizer’ function
will automatically detect it.  Note that the underscore must be
used as the tag component separator in this case, in order to
form a valid python module name. (e.g. “en_US” rather than “en-US”)</p>
<p>Currently, a tokenizer has only been implemented for the English
language.  Based on the author’s limited experience, this should
be at least partially suitable for other languages.</p>
<p>This module also provides various implementations of “Chunkers” and
“Filters”.  These classes are designed to make it easy to work with
text in a variety of common formats, by detecting and excluding parts
of the text that don’t need to be checked.</p>
<p>A Chunker is a class designed to break a body of text into large chunks
of checkable content; for example the HTMLChunker class extracts the
text content from all HTML tags but excludes the tags themselves.
A Filter is a class designed to skip individual words during the checking
process; for example the URLFilter class skips over any words that
have the format of a URL.</p>
<p>For example, to spellcheck an HTML document it is necessary to split the
text into chunks based on HTML tags, and to filter out common word forms
such as URLs and WikiWords.  This would look something like the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tknzr</span> <span class="o">=</span> <span class="n">get_tokenizer</span><span class="p">(</span><span class="s2">&quot;en_US&quot;</span><span class="p">,(</span><span class="n">HTMLChunker</span><span class="p">,),(</span><span class="n">URLFilter</span><span class="p">,</span><span class="n">WikiWordFilter</span><span class="p">)))</span>

<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;&lt;html&gt;&lt;body&gt;the url is http://example.com&lt;/body&gt;&lt;/html&gt;&quot;</span>
<span class="k">for</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span><span class="n">pos</span><span class="p">)</span> <span class="ow">in</span> <span class="n">tknzer</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="o">...</span><span class="n">check</span> <span class="n">each</span> <span class="n">word</span> <span class="ow">and</span> <span class="n">react</span> <span class="n">accordingly</span><span class="o">...</span>
</pre></div>
</div>
<dl class="py class">
<dt id="enchant.tokenize.Chunker">
<em class="property">class </em><code class="sig-prename descclassname">enchant.tokenize.</code><code class="sig-name descname">Chunker</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">text</span></em><span class="sig-paren">)</span><a class="headerlink" href="#enchant.tokenize.Chunker" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for text chunking functions.</p>
<p>A chunker is designed to chunk text into large blocks of tokens.  It
has the same interface as a tokenizer but is for a different purpose.</p>
</dd></dl>

<dl class="py class">
<dt id="enchant.tokenize.EmailFilter">
<em class="property">class </em><code class="sig-prename descclassname">enchant.tokenize.</code><code class="sig-name descname">EmailFilter</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tokenizer</span></em><span class="sig-paren">)</span><a class="headerlink" href="#enchant.tokenize.EmailFilter" title="Permalink to this definition">¶</a></dt>
<dd><p>Filter skipping over email addresses.
This filter skips any words matching the following regular expression:</p>
<blockquote>
<div><p>^.+&#64;[^.].*.[a-z]{2,}$</p>
</div></blockquote>
<p>That is, any words that resemble email addresses.</p>
</dd></dl>

<dl class="py class">
<dt id="enchant.tokenize.Filter">
<em class="property">class </em><code class="sig-prename descclassname">enchant.tokenize.</code><code class="sig-name descname">Filter</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tokenizer</span></em><span class="sig-paren">)</span><a class="headerlink" href="#enchant.tokenize.Filter" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for token filtering functions.</p>
<p>A filter is designed to wrap a tokenizer (or another filter) and do
two things:</p>
<blockquote>
<div><ul class="simple">
<li><p>skip over tokens</p></li>
<li><p>split tokens into sub-tokens</p></li>
</ul>
</div></blockquote>
<p>Subclasses have two basic options for customising their behaviour.  The
method _skip(word) may be overridden to return True for words that
should be skipped, and false otherwise.  The method _split(word) may
be overridden as tokenization function that will be applied to further
tokenize any words that aren’t skipped.</p>
</dd></dl>

<dl class="py class">
<dt id="enchant.tokenize.HTMLChunker">
<em class="property">class </em><code class="sig-prename descclassname">enchant.tokenize.</code><code class="sig-name descname">HTMLChunker</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">text</span></em><span class="sig-paren">)</span><a class="headerlink" href="#enchant.tokenize.HTMLChunker" title="Permalink to this definition">¶</a></dt>
<dd><p>Chunker for breaking up HTML documents into chunks of checkable text.</p>
<p>The operation of this chunker is very simple - anything between a “&lt;”
and a “&gt;” will be ignored.  Later versions may improve the algorithm
slightly.</p>
</dd></dl>

<dl class="py class">
<dt id="enchant.tokenize.HashtagFilter">
<em class="property">class </em><code class="sig-prename descclassname">enchant.tokenize.</code><code class="sig-name descname">HashtagFilter</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tokenizer</span></em><span class="sig-paren">)</span><a class="headerlink" href="#enchant.tokenize.HashtagFilter" title="Permalink to this definition">¶</a></dt>
<dd><p>Filter skipping over #hashtag.
This filter skips any words matching the following regular expression:</p>
<blockquote>
<div><p>(A|s)#(w+)</p>
</div></blockquote>
<p>That is, any words that are #hashtag.</p>
</dd></dl>

<dl class="py class">
<dt id="enchant.tokenize.MentionFilter">
<em class="property">class </em><code class="sig-prename descclassname">enchant.tokenize.</code><code class="sig-name descname">MentionFilter</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tokenizer</span></em><span class="sig-paren">)</span><a class="headerlink" href="#enchant.tokenize.MentionFilter" title="Permalink to this definition">¶</a></dt>
<dd><p>Filter skipping over &#64;mention.
This filter skips any words matching the following regular expression:</p>
<blockquote>
<div><p>(A|s)&#64;(w+)</p>
</div></blockquote>
<p>That is, any words that are &#64;mention.</p>
</dd></dl>

<dl class="py class">
<dt id="enchant.tokenize.URLFilter">
<em class="property">class </em><code class="sig-prename descclassname">enchant.tokenize.</code><code class="sig-name descname">URLFilter</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tokenizer</span></em><span class="sig-paren">)</span><a class="headerlink" href="#enchant.tokenize.URLFilter" title="Permalink to this definition">¶</a></dt>
<dd><p>Filter skipping over URLs.
This filter skips any words matching the following regular expression:</p>
<blockquote>
<div><p>^[a-zA-Z]+://[^s].*</p>
</div></blockquote>
<p>That is, any words that are URLs.</p>
</dd></dl>

<dl class="py class">
<dt id="enchant.tokenize.WikiWordFilter">
<em class="property">class </em><code class="sig-prename descclassname">enchant.tokenize.</code><code class="sig-name descname">WikiWordFilter</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tokenizer</span></em><span class="sig-paren">)</span><a class="headerlink" href="#enchant.tokenize.WikiWordFilter" title="Permalink to this definition">¶</a></dt>
<dd><p>Filter skipping over WikiWords.
This filter skips any words matching the following regular expression:</p>
<blockquote>
<div><p>^([A-Z]w+[A-Z]+w+)</p>
</div></blockquote>
<p>That is, any words that are WikiWords.</p>
</dd></dl>

<dl class="py class">
<dt id="enchant.tokenize.basic_tokenize">
<em class="property">class </em><code class="sig-prename descclassname">enchant.tokenize.</code><code class="sig-name descname">basic_tokenize</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">text</span></em><span class="sig-paren">)</span><a class="headerlink" href="#enchant.tokenize.basic_tokenize" title="Permalink to this definition">¶</a></dt>
<dd><p>Tokenizer class that performs very basic word-finding.</p>
<p>This tokenizer does the most basic thing that could work - it splits
text into words based on whitespace boundaries, and removes basic
punctuation symbols from the start and end of each word.</p>
</dd></dl>

<dl class="py class">
<dt id="enchant.tokenize.empty_tokenize">
<em class="property">class </em><code class="sig-prename descclassname">enchant.tokenize.</code><code class="sig-name descname">empty_tokenize</code><a class="headerlink" href="#enchant.tokenize.empty_tokenize" title="Permalink to this definition">¶</a></dt>
<dd><p>Tokenizer class that yields no elements.</p>
</dd></dl>

<dl class="py function">
<dt id="enchant.tokenize.get_tokenizer">
<code class="sig-prename descclassname">enchant.tokenize.</code><code class="sig-name descname">get_tokenizer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tag</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">chunkers</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">filters</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#enchant.tokenize.get_tokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Locate an appropriate tokenizer by language tag.</p>
<p>This requires importing the function ‘tokenize’ from an appropriate
module.  Modules tried are named after the language tag, tried in the
following order:</p>
<blockquote>
<div><ul class="simple">
<li><p>the entire tag (e.g. “en_AU.py”)</p></li>
<li><p>the base country code of the tag (e.g. “en.py”)</p></li>
</ul>
</div></blockquote>
<p>If the language tag is None, a default tokenizer (actually the English
one) is returned.  It’s unicode aware and should work OK for most
latin-derived languages.</p>
<p>If a suitable function cannot be found, raises TokenizerNotFoundError.</p>
<p>If given and not None, ‘chunkers’ and ‘filters’ must be lists of chunker
classes and filter classes respectively.  These will be applied to the
tokenizer during creation.</p>
</dd></dl>

<dl class="py class">
<dt id="enchant.tokenize.tokenize">
<em class="property">class </em><code class="sig-prename descclassname">enchant.tokenize.</code><code class="sig-name descname">tokenize</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">text</span></em><span class="sig-paren">)</span><a class="headerlink" href="#enchant.tokenize.tokenize" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for all tokenizer objects.</p>
<p>Each tokenizer must be an iterator and provide the ‘offset’
attribute as described in the documentation for this module.</p>
<p>While tokenizers are in fact classes, they should be treated
like functions, and so are named using lower_case rather than
the CamelCase more traditional of class names.</p>
</dd></dl>

<dl class="py class">
<dt id="enchant.tokenize.unit_tokenize">
<em class="property">class </em><code class="sig-prename descclassname">enchant.tokenize.</code><code class="sig-name descname">unit_tokenize</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">text</span></em><span class="sig-paren">)</span><a class="headerlink" href="#enchant.tokenize.unit_tokenize" title="Permalink to this definition">¶</a></dt>
<dd><p>Tokenizer class that yields the text as a single token.</p>
</dd></dl>

<dl class="py function">
<dt id="enchant.tokenize.wrap_tokenizer">
<code class="sig-prename descclassname">enchant.tokenize.</code><code class="sig-name descname">wrap_tokenizer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tk1</span></em>, <em class="sig-param"><span class="n">tk2</span></em><span class="sig-paren">)</span><a class="headerlink" href="#enchant.tokenize.wrap_tokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrap one tokenizer inside another.</p>
<p>This function takes two tokenizer functions ‘tk1’ and ‘tk2’,
and returns a new tokenizer function that passes the output
of tk1 through tk2 before yielding it to the calling code.</p>
</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="enchant.utils.html" class="btn btn-neutral float-right" title="enchant.utils: Misc utilities for the enchant package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="enchant.checker.html" class="btn btn-neutral float-left" title="enchant.checker: High-level spellchecking functionality" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2011, Ryan Kelly

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>